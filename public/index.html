<!DOCTYPE html>
<html lang="tr">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>TÃ¼rkÃ§e Realtime Sesli Bot</title>
  <style>
    body {
      font-family: sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 40px
    }

    button {
      padding: 10px 20px;
      font-size: 1rem;
      margin: 12px
    }

    #logs {
      width: 90%;
      max-width: 600px;
      height: 220px;
      overflow: auto;
      border: 1px solid #ccc;
      padding: 8px;
      font-size: .85rem;
      white-space: pre-wrap
    }
  </style>
</head>

<body>
  <h1>TÃ¼rkÃ§e Realtime Sesli Bot (WebRTC)</h1>
  <button id="startBtn">BaÄŸlanÂ +Â KonuÅŸ</button>
  <button id="stopBtn" disabled>Durdur</button>
  <div id="logs"></div>

  <script type="module">
    const startBtn = document.getElementById("startBtn");
    const stopBtn = document.getElementById("stopBtn");
    const logsEl = document.getElementById("logs");

    let pc, dc, localTrack, audioEl;

    function log(...args) {
      console.log(...args);
      logsEl.textContent += args.join(" ") + "\n";
      logsEl.scrollTop = logsEl.scrollHeight;
    }

    async function connect() {
      startBtn.disabled = true;
      stopBtn.disabled = false;

      // 1. Get an EPHEMERAL key & SDP answer from backend
      const { client_secret, id: sessionId } = await (await fetch("/session")).json();
      const EPHEMERAL_KEY = client_secret.value;

      // 2. Peer connection
      pc = new RTCPeerConnection();
      dc = pc.createDataChannel("oai-events");

      dc.onmessage = (e) => {
        const evt = JSON.parse(e.data);
        // For demo: show only highâ€‘level markers
        if (evt.type === "input_audio_buffer.speech_started") log("ðŸ—£ï¸  KonuÅŸma baÅŸladÄ±");
        if (evt.type === "input_audio_buffer.speech_stopped") log("ðŸ¤«  KonuÅŸma bitti");
        if (evt.type === "response.done") log("ðŸ”ˆ  YanÄ±t tamam");
        if (evt.type === "error") log("âš ï¸  Hata:", evt.message);
      };

      // 3. Remote audio -> play
      audioEl = new Audio();
      audioEl.autoplay = true;
      pc.ontrack = (e) => { audioEl.srcObject = e.streams[0]; };

      // 4. Local microphone
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      localTrack = stream.getTracks()[0];
      pc.addTrack(localTrack);

      // 5. Offer / Answer with SDPs
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      const sdpRes = await fetch(`https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17`, {
        method: "POST",
        body: offer.sdp,
        headers: {
          Authorization: `Bearer ${EPHEMERAL_KEY}`,
          "Content-Type": "application/sdp"
        },
      });
      const answer = { type: "answer", sdp: await sdpRes.text() };
      await pc.setRemoteDescription(answer);

      log("âœ…  BaÄŸlantÄ± kuruldu â€” Session:", sessionId);
    }

    function disconnect() {
      stopBtn.disabled = true;
      startBtn.disabled = false;
      if (dc) dc.close();
      if (pc) pc.close();
      if (localTrack) localTrack.stop();
      pc = dc = localTrack = null;
      log("â›”  BaÄŸlantÄ± kapatÄ±ldÄ±");
    }

    startBtn.onclick = connect;
    stopBtn.onclick = disconnect;
  </script>
</body>

</html>